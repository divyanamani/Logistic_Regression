{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lead Scoring with Logistic Regression\n",
    "##### Build a logistic regression model to assign a lead score between 0 and 100 to each of the leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 1. Reading and Understanding the Data](#step1)\n",
    "\n",
    "## [Step 2.Data Cleaning and EDA](#step2)\n",
    "[2.1 Missing value check](#step2.1)<br>\n",
    "[2.2 Cleaning and Visualizing categorical variables](#step2.2)<br>\n",
    "[2.3 Cleaning and Visualizing numerical variables](#step2.3)<br>\n",
    "[2.4 Outlier Treatment](#step2.4)<br>\n",
    "[2.5 Check for data type conversion](#step2.5)<br>\n",
    "\n",
    "## [Step 3. Preprocessing and Data Preparation](#step3)\n",
    "[3.1 Categorizing variables](#step3.1)<br>\n",
    "[3.2 Creating dummy variables](#step3.2)<br>\n",
    "[3.3 Train test split](#step3.3)<br>\n",
    "[3.4 Scaling data](#step3.4)<br>\n",
    "\n",
    "## [Step 4. Model Building](#Step4)\n",
    "[Step 4.1 Build Logistic Model](#step4.1)<br>\n",
    "[Step 4.2 Prediction and evaluation on Training Set](#step4.2)<br>\n",
    "[Step 4.3 Prediction and evaluation on Testing Set](#step4.3)<br>\n",
    "\n",
    "## [Step 5. Final Analysis](#Step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps will be covered to build the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Reading and Understanding the Data<a id='step1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data = pd.read_csv('Leads.csv')\n",
    "lead_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 37 columns,the bottom 5 from the above list are numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking data imbalance\n",
    "lead_data['Converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only 38% of the leads were converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lead_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming lengthy names of columns\n",
    "lead_data = lead_data.rename({'Total Time Spent on Website':'Website Time','What is your current occupation': 'Occupation','What matters most to you in choosing a course':'Reason','A free copy of Mastering The Interview':'Free copy required'}, axis=1)\n",
    "lead_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.Data Cleaning and EDA<a id='step2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Missing value check<a id=step2.1></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum it up to check how many rows have all missing values\n",
    "lead_data.isnull().all(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lead_data[lead_data.isnull().sum(axis=1)>5].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of the missing values (column-wise)\n",
    "round(100*(lead_data.isnull().sum()/len(lead_data.index)), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We do see lots of missing values and most of columns have greater than 20% missing values. Lets divide the columns into categorical and numerical and handle them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Cleaning and Visualizing categorical variables<a id='step2.2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping columns having > 45% missing values\n",
    "lead_data.drop(['Asymmetrique Activity Index','Asymmetrique Profile Index','Asymmetrique Activity Score','Asymmetrique Profile Score','Lead Quality'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Lead Origin', 'Lead Source','Do Not Email', 'Do Not Call', 'Last Activity',\n",
    "       'Country', 'Specialization', 'How did you hear about X Education',\n",
    "       'Occupation',\n",
    "       'Reason', 'Search', 'Magazine',\n",
    "       'Newspaper Article', 'X Education Forums', 'Newspaper',\n",
    "       'Digital Advertisement', 'Through Recommendations',\n",
    "       'Receive More Updates About Our Courses', 'Tags',\n",
    "       'Update me on Supply Chain Content', 'Get updates on DM Content',\n",
    "       'Lead Profile', 'City','I agree to pay the amount through cheque',\n",
    "       'Free copy required', 'Last Notable Activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check total counts, skewness and importance of a categorical column based on conversion rate. \n",
    "def check_count_conversion_rate(X):\n",
    "    #checking counts of col\n",
    "    col_counts = pd.DataFrame(lead_data[X].value_counts()).reset_index()\n",
    "    col_counts.columns = [X,'Counts']\n",
    "    col_counts['Total%'] = col_counts['Counts']/len(lead_data.index)\n",
    "    #checking conversion rate by col\n",
    "    groupby_col = pd.DataFrame(lead_data.groupby(X)['Converted'].mean()).reset_index()\n",
    "\n",
    "    col_counts_percentage = col_counts.merge(groupby_col,how='inner',on=X)\n",
    "    return col_counts_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_2_col_count_conversion_rate(X):\n",
    "    col_counts = pd.DataFrame(lead_data.groupby(X)[X[1]].count())\n",
    "    col_counts.columns = ['Counts']\n",
    "    col_counts.reset_index()\n",
    "     #checking conversion rate by col\n",
    "    groupby_col = pd.DataFrame(lead_data.groupby(X)['Converted'].mean()).reset_index()\n",
    "    groupby_col\n",
    "    col_counts_percentage = pd.merge(col_counts, groupby_col,  how='left', left_on=X, right_on = X)\n",
    "    return col_counts_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of `Select` in categorical columns are treated as null.Therefore, will convert `Select` value to `NaN` before checking the actual missing value percentage of a particular column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking skewed categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_skewness(X):\n",
    "    count_of_values = lead_data[X].value_counts().values\n",
    "    count_of_values = count_of_values/len(lead_data)\n",
    "    col_of_values = list(lead_data[X].value_counts().index)\n",
    "    dict_data = {}\n",
    "    for i in range(0,len(col_of_values)):\n",
    "        dict_data[col_of_values[i]] = count_of_values[i]\n",
    "    df = pd.DataFrame(data=dict_data,index=[X])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,20])\n",
    "skewness = []\n",
    "for i in range(0,len(cat_cols)):\n",
    "    ax = plt.subplot(6,5,i+1)\n",
    "    skewness.append(check_skewness(cat_cols[i]))\n",
    "    skewness[i].plot(kind='bar',stacked=True,ax = ax)\n",
    "    ax.legend().set_visible(False)\n",
    "    plt.xticks(rotation=0)\n",
    "    ax.set_ylim([0.0,1.0])\n",
    "plt.show()\n",
    "\n",
    "#check_skewness(cat_cols[4]).plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference:\n",
    "- We see lot of columns that are skewed and has only one value more than 90% of the time\n",
    "- The reason some bars are not 100% complete is because of the presence of null values.\n",
    "- Its better to delete highly skewed columns as they will not be helpfull in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting cols where 90% of the values are same\n",
    "skewed_cols = ['Do Not Email', 'Do Not Call',\n",
    "       'Reason', 'Search', 'Magazine',\n",
    "       'Newspaper Article', 'X Education Forums', 'Newspaper',\n",
    "       'Digital Advertisement', 'Through Recommendations',\n",
    "       'Receive More Updates About Our Courses',\n",
    "       'Update me on Supply Chain Content', 'Get updates on DM Content',\n",
    "       'I agree to pay the amount through cheque']\n",
    "lead_data.drop(skewed_cols,axis=1,inplace=True)\n",
    "lead_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in skewed_cols:\n",
    "    cat_cols.remove(i)\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting cols where missing % is greater than 45%\n",
    "# missing_45 = ['Lead Quality','Asymmetrique Activity Index','Asymmetrique Profile Index']\n",
    "# lead_data.drop(missing_45,axis=1,inplace=True)\n",
    "# print(\"final shape = {}\".format(lead_data.shape))\n",
    "# for i in missing_45:\n",
    "#     cat_cols.remove(i)\n",
    "# cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*(len(lead_data[lead_data[cat_cols].isnull().sum(axis=1)>6].index)/len(lead_data.index))\n",
    "len(lead_data[lead_data[cat_cols].isnull().sum(axis=1)>4].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Lead Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of missing values\n",
    "lead_data['Lead Source'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Lead Source').sort_values(by='Total%',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences:\n",
    "- Google is written as google in 5 values.\n",
    "- There are total 21 different values for the column\n",
    "- There are few of them which were used only once. Will to combine them into others later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#google to Google\n",
    "lead_data.loc[(lead_data['Lead Source'] == 'google'),['Lead Source']] = 'Google'\n",
    "lead_data['Lead Source'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Lead Source').sort_values(by='Converted',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences:\n",
    "- Welingak Website has the maximum conversion rate followed by Reference\n",
    "- Google and Direct Traffic has a top counts and a good conversion rate of ~35% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the relation `Lead Origin` and `Lead Source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Lead Origin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the counts of `Lead Source` based on `Lead Origin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_2_col_count_conversion_rate(['Lead Origin','Lead Source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We notice that Lead Source is highly affected by Lead Origin. Therefore, replacing the missing values of Lead Source by the mode of Lead Source depending on the Lead Origin\n",
    "\n",
    "    Lead Origin                 Mode of Lead Source\n",
    "    - API                        Olark Chat\n",
    "    - Landing Page Submission\tDirect Traffic\n",
    "    - Lead Add Form              Reference\n",
    "    - Lead Import                Facebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.loc[(pd.isnull(lead_data['Lead Source'])),['Lead Origin','Lead Source']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_source_mode_dict = dict({'API': 'Olark Chat', 'Landing Page Submission': 'Direct Traffic', 'Lead Add Form':'Reference','Lead Import':'Lead Import','Quick Add Form':'NaN'}) \n",
    "lead_data.loc[pd.isnull(lead_data['Lead Source']), ['Lead Source']] = lead_data.loc[pd.isnull(lead_data['Lead Source'])].apply(lambda x: origin_source_mode_dict[x['Lead Origin']],axis=1)\n",
    "check_2_col_count_conversion_rate(['Lead Origin','Lead Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting one row where Lead Origin is Quick Add form and Lead Source is Nan\n",
    "lead_data = lead_data.loc[lead_data['Lead Origin'] != 'Quick Add Form']\n",
    "lead_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling last Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of missing values\n",
    "lead_data['Last Activity'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastActivity = check_skewness('Last Activity')\n",
    "#print(df)\n",
    "ax = plt.subplot(1,1,1)\n",
    "lastActivity.plot(kind='bar',stacked=True,ax = ax)\n",
    "plt.xticks(rotation=0)\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.45, 1.1), shadow=True, ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastActivity.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 37% of rows have `Email Opened` as the value of `Last Activity`\n",
    "- Replacing 103 missing values of `Last Activity` with `Email Opened`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.loc[lead_data['Last Activity'].isnull(),['Last Activity']] = 'Email Opened'\n",
    "check_skewness('Last Activity').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Last Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_skewness('Country').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Missing country values: {}'.format(lead_data['Country'].isnull().sum()))\n",
    "print('Rows where country and city both are missing: {}'.format(len(lead_data.loc[(lead_data['Country'].isnull() & lead_data['City'].isnull())])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country seems to be an important columns as Countries like India, US, Singapore have greater than 30% conversion rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('City')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing missing value of `Country` with 'Unknown' where `City` value is also missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.loc[(lead_data['Country'].isnull() & lead_data['City'].isnull()),['Country']] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lead_data.loc[(lead_data['Country'].isnull() & lead_data['City'].isnull())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_country(x):\n",
    "    if x['City'] in ['Mumbai' ,'Thane & Outskirts','Other Cities of Maharashtra']:\n",
    "        return 'India'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "    \n",
    "lead_data.loc[lead_data['Country'].isnull(),['Country']] = lead_data.loc[lead_data['Country'].isnull(),['Country','City']].apply(lambda x: handle_country(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unkown also comes in missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### out of 2461 missing value of Country 2131 countries are still unknown and rest are substituted with 'India' as the city column for these have Indian references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Specialization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value `Select` acts as missing value. First let is replace missing values with Select\n",
    "lead_data.loc[pd.isnull(lead_data['Specialization']),['Specialization']] = 'Select'\n",
    "check_count_conversion_rate('Specialization') .sort_values(by='Total%',ascending=False)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From above table we can see that Actual missing % of Specialization = 36.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastActivity = check_skewness('Specialization')\n",
    "#print(df)\n",
    "ax = plt.subplot(1,1,1)\n",
    "lastActivity.plot(kind='bar',stacked=True,ax = ax)\n",
    "plt.xticks(rotation=0)\n",
    "ax.set_ylim([0.0,1.0])\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.45, 1.1), shadow=True, ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The maximum % is still missing with value as (Select). As the percentage is large will replace these missing value with `others`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### replacing select with Others\n",
    "\n",
    "lead_data.loc[lead_data['Specialization']=='Select','Specialization']='Others'\n",
    "check_skewness('Specialization').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling `How did you hear about X Education`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('How did you hear about X Education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.loc[pd.isnull(lead_data['How did you hear about X Education']),['How did you hear about X Education']] = 'Select'\n",
    "check_count_conversion_rate('How did you hear about X Education') .sort_values(by='Total%',ascending=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 78% of values for `How did you hear about X Education` is missing. Therefore deleting this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.drop(['How did you hear about X Education'],axis=1,inplace=True)\n",
    "print(lead_data.shape)\n",
    "\n",
    "cat_cols.remove('How did you hear about X Education')\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Occupation               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Occupation'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Occupation') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferences:\n",
    "- 60% of leads are Unemployed and they have good conversion rate of 43%\n",
    "- Though number of working professional is less, but their conversion rate is higher at 91%\n",
    "- The missing percentage is 29%. Replacing with mode might skew the data.\n",
    "- Therefore, Replacing null values in Occupation with value `Other`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.loc[pd.isnull(lead_data['Occupation']),['Occupation']] = 'Other'\n",
    "check_count_conversion_rate('Occupation') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Tags                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Tags'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Tags').sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.loc[pd.isnull(lead_data['Tags']),['Tags']] = 'Others'\n",
    "check_count_conversion_rate('Tags') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp=check_count_conversion_rate('Tags') .sort_values(by='Total%',ascending=False)\n",
    "#exp.to_csv('analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Lead Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Lead Profile'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('Lead Profile') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nans with select to get total missing percentage\n",
    "lead_data.loc[pd.isnull(lead_data['Lead Profile']),['Lead Profile']] = 'Select'\n",
    "check_count_conversion_rate('Lead Profile') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 74% of the data is missing for column `Lead Profile`, therefore, deleting the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.drop(['Lead Profile'],axis=1,inplace=True)\n",
    "print(lead_data.shape)\n",
    "\n",
    "cat_cols.remove('Lead Profile')\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling City                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['City'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('City') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing nans with select to get total count\n",
    "lead_data.loc[pd.isnull(lead_data['City']),['City']] = 'Select'\n",
    "check_count_conversion_rate('City') .sort_values(by='Total%',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.countplot(x='City',hue='Converted',data=lead_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "- Close to 40% of the values are missing\n",
    "- Each value have equal probaility of conversion(~40%), which might not help in prediction\n",
    "- As city column is not adding value, deleting the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.drop(['City'],axis=1,inplace=True)\n",
    "print(lead_data.shape)\n",
    "\n",
    "cat_cols.remove('City')\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Notable Activity is an intermediate column which is an update while the sales team representative is in touch with the lead. Last Activity is a column that talks about the last activity when the lead was closed from the sales team side. Therefore,using only Last Activity column as it shows the final decision when the lead was closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.drop('Last Notable Activity',axis=1,inplace=True)\n",
    "cat_cols.remove('Last Notable Activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(lead_data[cat_cols].isnull().sum()/len(lead_data.index)), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Till now \n",
    "- only 1 row deleted\n",
    "- 20 columns deleted(14 skewed, 5 missing >45, 1 based on data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Cleaning and Visualizing numerical variables<a id='step2.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['TotalVisits'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['TotalVisits','Website Time','Page Views Per Visit']\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Visits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualising Total visits data \n",
    "lead_data['TotalVisits'].value_counts()\n",
    "#lead_data['TotalVisits'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysing Total visits data \n",
    "lead_data['TotalVisits'].median() ##3.0\n",
    "lead_data['TotalVisits'].mean() ##3.45\n",
    "## Since the Total visits cannot be fractional,replacing with 3 considering both mean and median values\n",
    "lead_data.loc[pd.isnull(lead_data['TotalVisits']),'TotalVisits']=lead_data['TotalVisits'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['TotalVisits'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page Views Per Visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Page Views Per Visit'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Page Views Per Visit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysing Page views per visit data\n",
    "lead_data['Page Views Per Visit'].median() ## 2.0\n",
    "lead_data['Page Views Per Visit'].mean() ## 2.36\n",
    "lead_data.loc[pd.isnull(lead_data['TotalVisits']),'TotalVisits']=lead_data['TotalVisits'].median()\n",
    "lead_data.loc[pd.isnull(lead_data['Page Views Per Visit']),'Page Views Per Visit']=lead_data['Page Views Per Visit'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Page Views Per Visit'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Lead Source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Outlier Treatment<a id='step2.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for col in num_cols:\n",
    "    plt.subplot(2,3,num_cols.index(col)+1)\n",
    "    sns.boxplot(y=col,data=lead_data,palette='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "Total Visits and Page views per visit have Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data[['TotalVisits','Page Views Per Visit']].describe(percentiles=(0.95,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['TotalVisits'].value_counts(ascending=False)\n",
    "\n",
    "## capping at 99% value - 17\n",
    "\n",
    "lead_data.loc[lead_data['TotalVisits']>17,['TotalVisits']]=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_data['TotalVisits'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capping at 99% value - 9\n",
    "\n",
    "lead_data.loc[lead_data['Page Views Per Visit']>9,'Page Views Per Visit']=9\n",
    "lead_data['Page Views Per Visit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Replotting the box plots\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for col in num_cols:\n",
    "    plt.subplot(2,3,num_cols.index(col)+1)\n",
    "    sns.boxplot(y=col,data=lead_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Check for data type conversion<a id='step2.5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lead_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation : \n",
    "No datatype conversion required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Preprocessing and Data Preparation<a id='step3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Categorizing variables<a id='step3.1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lead source grouping into others category\n",
    "values=lead_data['Lead Source'].value_counts()\n",
    "#type(values)\n",
    "val=values[values.lt(7)].index\n",
    "#val\n",
    "lead_data.loc[lead_data['Lead Source'].isin(val),'Lead Source']='Others'\n",
    "lead_data['Lead Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country categorization\n",
    "check_count_conversion_rate('Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 37 different countries and many have very few data. Clubbing them together based on the continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asia=['Singapore',\n",
    "'Saudi Arabia',\n",
    "'Qatar',\n",
    "'Bahrain', \n",
    "'Hong Kong', \n",
    "'Oman', \n",
    "'Kuwait',\n",
    "'Philippines', \n",
    "'Bangladesh', \n",
    "'Asia/Pacific Region',\n",
    "'China', \n",
    "'Malaysia',  \n",
    "'Russia',\n",
    "'Vietnam',\n",
    "'Indonesia',\n",
    "'Sri Lanka',\n",
    "'United Arab Emirates']\n",
    "\n",
    "africa= ['Kenya',\n",
    "'South Africa',\n",
    "'Nigeria',\n",
    "'Uganda',\n",
    "'Ghana',\n",
    "'Tanzania',\n",
    "'Liberia']\n",
    "\n",
    "europe = ['United Kingdom',\n",
    "'France',\n",
    "'Germany',\n",
    "'Sweden',\n",
    "'Netherlands',\n",
    "'Belgium',\n",
    "'Italy',\n",
    "'Switzerland',\n",
    "'Denmark']\n",
    "\n",
    "north_america = ['United States','Canada']\n",
    "\n",
    "def categorize_country(x):\n",
    "    if x in asia:\n",
    "        return 'Asia'\n",
    "    elif x in africa:\n",
    "        return 'Africa'\n",
    "    elif x in europe:\n",
    "        return 'Europe'\n",
    "    elif x in north_america:\n",
    "        return 'North_america'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "lead_data['country_categorized'] = lead_data['Country'].apply(lambda x: categorize_country(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_count_conversion_rate('country_categorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data[['Country','country_categorized']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Country'] = lead_data['country_categorized']\n",
    "lead_data['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tags categorization\n",
    "check_count_conversion_rate('Tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 27 different values of Tags. We will be bucketing them into following categories based upon the business knowledge\n",
    "\n",
    "- Interested\n",
    "- Busy\n",
    "- Probable\n",
    "- Lost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested = ['Will revert after reading the email','Interested in other courses',\n",
    "              'Closed by Horizzon',\n",
    "              'Want to take admission but has financial problems',\n",
    "              'Still Thinking',  \n",
    "              'In confusion whether part time or DLP',\n",
    "              'Interested in Next batch',\n",
    "              'Shall take in the next coming month',\n",
    "              'University not recognized']\n",
    "lost = ['Lost to EINS','invalid number',\n",
    "        'Diploma holder (Not Eligible)',\n",
    "        'number not provided',\n",
    "        'wrong number given',\n",
    "        'Lost to Others',\n",
    "        'Already a student']\n",
    "busy = ['Busy',\n",
    "        'opp hangup']\n",
    "probable = ['Not doing further education',\n",
    "            'Interested  in full time MBA',\n",
    "            'Graduation in progress',\n",
    "            'in touch with EINS','Lateral student',\n",
    "           'Recognition issue (DEC approval)']\n",
    "def categorize_tags(x):\n",
    "    if x in interested:\n",
    "        return 'interested'\n",
    "    elif x in lost:\n",
    "        return 'lost'\n",
    "    elif x in busy:\n",
    "        return 'busy'\n",
    "    elif x in probable:\n",
    "        return 'probable'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "lead_data['tags_categorized'] = lead_data['Tags'].apply(lambda x: categorize_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['tags_categorized'].value_counts()\n",
    "check_count_conversion_rate('tags_categorized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data[['Tags','tags_categorized']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Tags'] = lead_data['tags_categorized']\n",
    "lead_data['Tags'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.drop(['tags_categorized','country_categorized'],axis=1,inplace=True)\n",
    "lead_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Creating dummy variables <a id='step3.3' ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Binary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating dummies for binary columns with Yes/No values\n",
    "binary_cols=['Free copy required']\n",
    "binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_cols:\n",
    "    lead_data[col]=lead_data[col].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data['Free copy required'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.remove('Free copy required')\n",
    "cols_with_others = ['Lead Source','Tags','Specialization','Country','Occupation']\n",
    "for col in cat_cols:\n",
    "    if col not in cols_with_others:\n",
    "        dummies=pd.get_dummies(lead_data[col],prefix=col,drop_first=True)\n",
    "        lead_data=pd.concat([lead_data,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting others value from dummy variables\n",
    "for col in cols_with_others:\n",
    "    dummies=pd.get_dummies(lead_data[col],prefix=col)\n",
    "    lead_data=pd.concat([lead_data,dummies],axis=1)    \n",
    "\n",
    "lead_data.drop(['Lead Source_Others','Tags_Others','Specialization_Others','Country_unknown','Occupation_Other'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lead_data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping redundant columns - final step of cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_data.drop(cat_cols,inplace=True,axis=1)\n",
    "lead_data.drop('Prospect ID',inplace=True,axis=1) ## some more to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=lead_data.pop('Converted')\n",
    "lead_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Train test split<a id='step3.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(lead_data,y,train_size=0.7,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Scaling data<a id='step3.4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling=StandardScaler()\n",
    "X_train[num_cols]=scaling.fit_transform(X_train[num_cols])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Model Building<a id='step4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.1  Build a Logistic Model<a id='step4.1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running the first time\n",
    "logm=sm.GLM(y_train,sm.add_constant(X_train),family=sm.families.Binomial())\n",
    "logm.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduce_best_model(y_train,X_train_rfe,drop_column=''):\n",
    "    \n",
    "    #X_train_rfe_trials=X_train_rfe\n",
    "    if drop_column!='':\n",
    "        X_train_rfe=X_train_rfe.drop(drop_column,axis=1)\n",
    "    lm=sm.GLM(y_train,X_train_rfe,family=sm.families.Binomial()).fit()\n",
    "    print(lm.summary())\n",
    "    \n",
    "    X_train_new=X_train_rfe.drop(['const'],axis=1)\n",
    "#X_train_new\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    print(\"-------------------------VIF Results-------------------------\")\n",
    "    vif=pd.DataFrame()\n",
    "    temp=X_train_new\n",
    "    vif['Columns']=temp.columns\n",
    "    vif['VIF']=[variance_inflation_factor(temp.values,i) for i in range(temp.shape[1])]\n",
    "    vif['VIF']=round(vif['VIF'],2)\n",
    "    vif=vif.sort_values(by='VIF',ascending=False)\n",
    "    print(vif)\n",
    "    return X_train_rfe,lm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(50,50))\n",
    "#sns.heatmap(lead_data.corr(),annot = True, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression()\n",
    "rfe=RFE(log_reg,20)\n",
    "rfe=rfe.fit(X_train,y_train)\n",
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe=X_train[cols]\n",
    "X_train_rfe=sm.add_constant(X_train_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking corelations on columns selected by rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(X_train[cols].corr(),annot = True, cmap=\"YlGnBu\",annot_kws={\"size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm1=deduce_best_model(y_train,X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Lead Number' as it has high VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Lead Number') ## Dropping 'Lead Number' as it has high VIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Last Activity_Page Visited on Website' as it has high p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Last Activity_Page Visited on Website')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Lead Origin_Lead Add Form' as it has high VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Lead Origin_Lead Add Form') ## Dropping 'Lead Number' as it has high VIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Country_India' as it has high VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Country_India') ## Dropping 'Lead Number' as it has high VIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Tags_lost' as it has high p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Tags_lost') ## Dropping 'Tags_lost' as it has high VIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Lead Source_Direct Traffic' as it has high p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Lead Source_Direct Traffic') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'Lead Origin_Landing Page Submission' as it has high VIF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'Lead Origin_Landing Page Submission') ## Dropping 'Lead Number' as it has high VIF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping 'TotalVisits' as it has high p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe,lm2=deduce_best_model(y_train,X_train_rfe,'TotalVisits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above model is the final model as all variables are significant and the VIF values are all less than 2.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4.2 Prediction and evaluation on Training Set<a id='Step4.2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic model predict the probabilities for the target variable 'Converted' being `1`\n",
    "Will convert the predicted values to an array and perform some analysis to check the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predicted values on train set\n",
    "y_train_pred=lm2.predict(X_train_rfe).values.reshape(-1)\n",
    "y_train_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will predict the value of `Converted` as 0 or 1 based on the probabilities predicted.\n",
    "\n",
    "- First we will create a dataframe with actual Converted flag and the predicted probabilities which will act as `Lead Score`\n",
    "- Then we will create a new column `predicted Converted` with 0 if predicted probability <= 0.5 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train['predicted']=y_train_pred\n",
    "y_train_pred_final = pd.DataFrame({'Actual_Converted':y_train.values,'Lead Score':y_train_pred,'Lead Number':X_train['Lead Number']})\n",
    "y_train_pred_final['ID'] = y_train.index\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Lead Score'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Lead Number'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Observing the top rows that gives cumulative probability of 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.to_csv('pred_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding optimal cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_train_pred_final[i]= y_train_pred_final['Lead Score'].map(lambda x: 1 if x > i else 0)\n",
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df = pd.DataFrame( columns = ['prob','accuracy','sensi','speci'])\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# TP = confusion[1,1] # true positive \n",
    "# TN = confusion[0,0] # true negatives\n",
    "# FP = confusion[0,1] # false positives\n",
    "# FN = confusion[1,0] # false negatives\n",
    "\n",
    "num = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for i in num:\n",
    "    cm1 = metrics.confusion_matrix(y_train_pred_final['Actual_Converted'], y_train_pred_final[i] )\n",
    "    total1=sum(sum(cm1))\n",
    "    accuracy = (cm1[0,0]+cm1[1,1])/total1\n",
    "    \n",
    "    speci = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    sensi = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\n",
    "print(cutoff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_df.plot.line(x='prob', y=['accuracy','sensi','speci'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value 3.5 seems to be a ood cutoff as all the metrics values are intersecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final['Predicted_Converted'] = y_train_pred_final['Lead Score'].map( lambda x: 1 if x > 0.35 else 0)\n",
    "y_train_pred_final['Predicted_Converted'].value_counts()\n",
    "y_train_pred_final['Lead Number']=X_train['Lead Number']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Lead Number'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Metrics on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "accu_train = metrics.accuracy_score(y_train_pred_final.Actual_Converted, y_train_pred_final.Predicted_Converted)\n",
    "\n",
    "confusion_mat = metrics.confusion_matrix(y_train_pred_final.Actual_Converted, y_train_pred_final.Predicted_Converted)\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy = {}\".format(accu_train))\n",
    "TP = confusion_mat[1,1] # true positive \n",
    "TN = confusion_mat[0,0] # true negatives\n",
    "FP = confusion_mat[0,1] # false positives\n",
    "FN = confusion_mat[1,0] # false negatives\\\n",
    "\n",
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\"Training Sensitivity: {}\".format(TP / float(TP+FN)))\n",
    "# Let us calculate specificity\n",
    "print(\"Training Specificity: {}\".format(TN / float(TN+FP)))\n",
    "# Calculate false postive rate - predicting churn when customer does not have churned\n",
    "print(FP/ float(TN+FP))\n",
    "# Positive predictive value \n",
    "print (TP / float(TP+FP))\n",
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_pred_final.Actual_Converted, y_train_pred_final.Predicted_Converted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The f1 score of training is 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_roc(actual_value,pred_prob):\n",
    "    fpr,tpr,thresholds = metrics.roc_curve(actual_value,pred_prob,drop_intermediate = False)\n",
    "    auc_score = metrics.roc_auc_score(actual_value,pred_prob)\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thresholds = metrics.roc_curve(y_train_pred_final.Actual_Converted,y_train_pred_final['Lead Score'],drop_intermediate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc(y_train_pred_final.Actual_Converted,y_train_pred_final['Lead Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ROC curve area is 93% which is good enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 4.3 Prediction and evaluation on Testing Set<a id='step4.3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=X_train_rfe.columns\n",
    "cols=cols.drop('const')\n",
    "X_test[['TotalVisits','Website Time','Page Views Per Visit']]=scaling.transform(X_test[['TotalVisits','Website Time','Page Views Per Visit']])\n",
    "X_test_tp=X_test\n",
    "X_test=X_test[cols]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm=sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred=lm2.predict(X_test_sm)\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final=pd.DataFrame({'Actual_Converted':y_test,'Lead Score':y_test_pred,'Lead Number':X_test_tp['Lead Number']})\n",
    "\n",
    "numbers = [float(x)/10 for x in range(10)]\n",
    "for i in numbers:\n",
    "    y_test_pred_final[i]= y_test_pred_final['Lead Score'].map(lambda x: 1 if x > i else 0)\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final['Predicted_Converted'] = y_test_pred_final['Lead Score'].map(lambda x: 1 if x > 0.35 else 0)\n",
    "#y_test_pred_final['Lead Number']=X_test['Lead Number']\n",
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final['Lead Number'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the overall accuracy.\n",
    "accu_train = metrics.accuracy_score(y_test_pred_final.Actual_Converted, y_test_pred_final.Predicted_Converted)\n",
    "\n",
    "confusion_mat = metrics.confusion_matrix(y_test_pred_final.Actual_Converted, y_test_pred_final.Predicted_Converted)\n",
    "confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracy = {}\".format(accu_train))\n",
    "TP = confusion_mat[1,1] # true positive \n",
    "TN = confusion_mat[0,0] # true negatives\n",
    "FP = confusion_mat[0,1] # false positives\n",
    "FN = confusion_mat[1,0] # false negatives\\\n",
    "\n",
    "# Let's see the sensitivity of our logistic regression model\n",
    "print(\"Testing Sensitivity: {}\".format(TP / float(TP+FN)))\n",
    "# Let us calculate specificity\n",
    "print(\"Testing Specificity: {}\".format(TN / float(TN+FP)))\n",
    "# Calculate false postive rate -\n",
    "print(FP/ float(TN+FP))\n",
    "# Positive predictive value \n",
    "print (TP / float(TP+FP))\n",
    "# Negative predictive value\n",
    "print (TN / float(TN+ FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_pred_final.Actual_Converted, y_test_pred_final.Predicted_Converted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score of test data is 84%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Final Analysis:<a id='Step5'></a>\n",
    "         Features                           \tCoeff\n",
    "            - Tags_interested                        2.2906 \t\t\t \n",
    "            - Lead Source_Olark Chat                 0.7507\t\t\t \n",
    "            - Last Activity_Email Opened             0.7293\n",
    "            - Last Activity_SMS Sent                 2.2233\n",
    "            - Free copy required                    -0.3246\n",
    "            - Last Activity_Olark Chat Conversation -1.1362\n",
    "            - Lead Source_Reference                  2.3124\n",
    "            - Website Time                           0.9219\n",
    "            - Occupation_Working Professional        1.7101\n",
    "            - Tags_Ringing                          -3.1427\n",
    "            - Last Activity_Converted to Lead       -0.9456\n",
    "            - Tags_probable                         -1.6866"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on log odd equation:\n",
    "    \n",
    "$ ln(P / 1− P) = β0 + β1 \\times x1 + β2 \\times x2 + β3 \\times x3 .. β12 \\times x12 $\n",
    "\n",
    "where \n",
    "    β1.. β12 are the coefficients of above 12 features\n",
    "    \n",
    "The odds of a lead getting converted (P/1-P), indicate how much likelier a lead is to get converted than to not convert. For example, if for a lead  whose odds of getting converted are equal to 3, \n",
    "i.e he is 3 times more likely to get converted than not to get converted. \n",
    "\n",
    "P(Conversion) = 3 * P(No Conversion).\n",
    "\n",
    "top features that increases the probabilty are\n",
    "\n",
    "- Lead Source_Reference (currently 91% conversion rate)\n",
    "- Tags_interested (currently  80% conversion rate)\n",
    "- Last Activity_SMS Sent (currently  63% conversion rate)\n",
    "- Website Time\n",
    "    \n",
    "top features that decreases the probabilty are\n",
    "    \n",
    "- Tags_Ringing (currently 2% conversion rate)\n",
    "- Tags_probable (currently 4% coversion rate)\n",
    "- Last Activity_Olark Chat Conversation (currently 8% conversion rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding lead score value to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_output = pd.concat([y_train_pred_final[['Lead Number','Lead Score']],y_test_pred_final[['Lead Number','Lead Score']]],axis=0)\n",
    "Final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "Final_output['Lead Score']=Final_output['Lead Score']*100\n",
    "Final_output['Lead Score']=Final_output['Lead Score'].map(lambda x:math.ceil(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_output['Lead Score'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_output=Final_output.sort_values(by='Lead Score',ascending=False)\n",
    "Final_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_output.to_csv('Final_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
